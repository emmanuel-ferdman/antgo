{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANTGO 开发流水线\n",
    "## ANTGO 环境安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装antgo库\n",
    "!pip3 install antgo@git+https://github.com/jianzfb/antgo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装docker环境\n",
    "!pip3 install udocker\n",
    "!udocker --allow-root install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装android扩展依赖\n",
    "!cd / && wget https://dl.google.com/android/repository/android-ndk-r20b-linux-x86_64.zip && unzip android-ndk-r20b-linux-x86_64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装C++扩展依赖\n",
    "!antgo install opencv\n",
    "!antgo install eigen\n",
    "!antgo install grpc\n",
    "!antgo install ffmpeg\n",
    "!antgo install eagleeye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 挂载google drive并设置工作目录\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "os.makedirs('/content/drive/MyDrive/workspace', exist_ok=True)\n",
    "# 如果已经创建了项目，则直接将项目目录设置为工作目录\n",
    "os.chdir(\"/content/drive/MyDrive/workspace/{{project}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTGO 环境配置（远程GPU训练部署集群）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置远程训练平台\n",
    "# ssh 模式\n",
    "# step 1: 生成ssh提交配置模板，执行后在当前目录生成ssh-submit-config.yaml\n",
    "!antgo submitter template\n",
    "# step 2: 填写模板\n",
    "'''\n",
    "username,ip 登录用户名和ip地址。提交后自动创建ssh-key，并设置免密登录。期间会\n",
    "要求填写密码操作（仅需一次）。\n",
    "config:\n",
    "  username: ''\n",
    "  password: ''\n",
    "  ip: ''\n",
    "\n",
    "script: ''\n",
    "image: ''\n",
    "'''\n",
    "# step 3: 更新配置\n",
    "!antgo submitter update --config=./ssh-submit-config.yaml\n",
    "\n",
    "# step 4: 查看远程机器\n",
    "!antgo ls\n",
    "\n",
    "# k8s 模式(即将支持)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型研发第一步：神经网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模板项目\n",
    "#### 创建分类项目\n",
    "```\n",
    "!cd /content/drive/MyDrive/workspace/cifar10\n",
    "!os.chdir(\"/content/drive/MyDrive/workspace/cifar10\")\n",
    "!antgo create mvp --name=cifar10\n",
    "```\n",
    "#### 创建目标检测项目\n",
    "```\n",
    "!cd /content/drive/MyDrive/workspace/coco\n",
    "!os.chdir(\"/content/drive/MyDrive/workspace/coco\")\n",
    "!antgo create mvp --name=coco\n",
    "```\n",
    "#### 创建关键点检测项目\n",
    "```\n",
    "!cd /content/drive/MyDrive/workspace/lsp\n",
    "!os.chdir(\"/content/drive/MyDrive/workspace/lsp\")\n",
    "!antgo create mvp --name=lsp\n",
    "```\n",
    "#### 创建语义分割项目\n",
    "```\n",
    "!cd /content/drive/MyDrive/workspace/pascal_voc\n",
    "!os.chdir(\"/content/drive/MyDrive/workspace/pascal_voc\")\n",
    "!antgo create mvp --name=pascal_voc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度神经网络模型训练\n",
    "!antgo train --exp=experiment_name --config=experiment_config --gpu-id=0 --no-validate --version=master --ip=remote_machine_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型测试脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度神经网络模型测试\n",
    "!antgo export --exp=experiment_name --config=experiment_config --checkpoint=checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型导出脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度神经网络模式导出\n",
    "!antgo export --exp=experiment_name --config=experiment_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型研发第二部：管线服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 管线创建和运行\n",
    "> 常用来快速验证模型或功能代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from antgo.pipeline import *\n",
    "# 服务管线创建并执行\n",
    "def debug_show(depth_pred):\n",
    "    depth_pred = depth_pred[0,0]\n",
    "    depth_pred = depth_pred / np.max(depth_pred)\n",
    "    depth_pred = np.clip(depth_pred * 255,0,255)\n",
    "    cv2.imwrite('./depth_pred.png', depth_pred.astype(np.uint8))\n",
    "\n",
    "# 下载图片和模型\n",
    "if not os.path.exists('./office.jpeg'):\n",
    "  !wget http://file.vibstring.com/office.jpeg\n",
    "if not os.path.exists('./depth_est.onnx'):\n",
    "  !wget http://file.vibstring.com/depth_est.onnx\n",
    "\n",
    "# 管线搭建和运行\n",
    "# 常用数据源imread_dc, video_dc, glob\n",
    "# imread_dc 图像读取\n",
    "# video_dc  视频读取\n",
    "# glob      文件读取 \n",
    "imread_dc['image']('./office.jpeg'). \\\n",
    "    resize_op['image', 'resized_image'](out_size=(640,480)). \\\n",
    "    inference_onnx_op['resized_image', ('depth_pred')](\n",
    "        onnx_path='./depth_est.onnx', \n",
    "        mean=[0.485*255, 0.456*255, 0.406*255],\n",
    "        std=[0.229*255, 0.224*255, 0.225*255]\n",
    "    ). \\\n",
    "    runas_op['depth_pred', 'o'](func=debug_show). \\\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 管线SDK构建打包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 管线SDK编译\n",
    "> 需要设置目标平台 android/arm64-v8a, linux/x86-64, linux/arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# android/arm64-v8a\n",
    "# 模型引擎可选: snpe, tnn, rknn\n",
    "# linux/x86-64\n",
    "# 模型引擎可选: tensorrt\n",
    "# linux/arm64\n",
    "# 模型引擎可选: tensorrt, rknn\n",
    "placeholder['image'](np.zeros((480,640,3), dtype=np.uint8)). \\\n",
    "    resize_op['image', 'resized_image'](out_size=(640,480)). \\\n",
    "    inference_onnx_op['resized_image', ('depth_pred')](\n",
    "        onnx_path='./depth_est.onnx', \n",
    "        mean=[0.485*255, 0.456*255, 0.406*255],\n",
    "        std=[0.229*255, 0.224*255, 0.225*255],\n",
    "        engine='tensorrt'\n",
    "    ). \\\n",
    "    build(\n",
    "        platform='linux/x86-64',\n",
    "        project_config={\n",
    "            'input': [\n",
    "                ('image', 'EAGLEEYE_SIGNAL_RGB_IMAGE'),\n",
    "            ],\n",
    "            'output': [\n",
    "                ('depth_pred', 'EAGLEEYE_SIGNAL_TENSOR')\n",
    "            ],\n",
    "            'name': 'metricdepth',\n",
    "            'git': ''\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 管线SDK打包\n",
    "> 支持android/sdk, linux/sdk\n",
    "\n",
    "> 需要根据编译时指定的目标来进行设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将相关文件打包到package文件夹下\n",
    "!antgo package --name=metricdepth --mode=linux/sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 管线WEB服务打包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建server文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir server\n",
    "os.chdir(\"./server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编写服务管线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile server.py\n",
    "from antgo.pipeline import *\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "# 创建web云端部署\n",
    "def convert_depth_to_show(depth_pred):\n",
    "    depth_pred = depth_pred[0,0]\n",
    "    depth_pred = depth_pred / np.max(depth_pred)\n",
    "    depth_pred = np.clip(depth_pred * 255,0,255)\n",
    "    cv2.imwrite('./depth_pred.png', depth_pred.astype(np.uint8))\n",
    "\n",
    "with web['image'](name='demo') as handler:\n",
    "    app = handler.resize_op['image', 'resized_image'](out_size=(640,480)). \\\n",
    "    inference_onnx_op['resized_image', ('depth_pred')](\n",
    "        onnx_path='../depth_est.onnx',\n",
    "        mean=[0.485*255, 0.456*255, 0.406*255],\n",
    "        std=[0.229*255, 0.224*255, 0.225*255]\n",
    "    ). \\\n",
    "    runas_op['depth_pred', 'depth_image'](func=convert_depth_to_show). \\\n",
    "    demo(\n",
    "        title=\"深度估计\",\n",
    "        description=\"深度估计DEMO\",\n",
    "\t\tinput=[\n",
    "\t\t\t{'data': 'image', 'type': 'image'},\n",
    "\t\t],\n",
    "\t\toutput=[\n",
    "\t\t\t{'data': 'depth_image', 'type': 'image'},\n",
    "\t\t]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 启动web服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "!antgo web --main=server:app --port=8080 --ngrok --authtoken=Your Ngrok token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打包服务\n",
    "> 打包后生成depth镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!antgo package --name=metricdepth --main=server:app --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 部署服务\n",
    "> 将创建的depth镜像推送到部署机器并部署（需要docker支持）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!antgo deploy --ip=remote_machine_ip --port=80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 管线私有化打包\n",
    "> grpc服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编写服务管线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder['image'](np.zeros((480,640,3), dtype=np.uint8)). \\\n",
    "    resize_op['image', 'resized_image'](out_size=(640,480)). \\\n",
    "    inference_onnx_op['resized_image', ('depth_pred')](\n",
    "        onnx_path='./depth_est.onnx', \n",
    "        mean=[0.485*255, 0.456*255, 0.406*255],\n",
    "        std=[0.229*255, 0.224*255, 0.225*255],\n",
    "        engine='tensorrt'\n",
    "    ). \\\n",
    "    build(\n",
    "        platform='linux/x86-64',\n",
    "        project_config={\n",
    "            'input': [\n",
    "                ('image', 'EAGLEEYE_SIGNAL_RGB_IMAGE'),\n",
    "            ],\n",
    "            'output': [\n",
    "                ('depth_pred', 'EAGLEEYE_SIGNAL_TENSOR')\n",
    "            ],\n",
    "            'name': 'metricdepth',\n",
    "            'git': '',\n",
    "            'mode': 'server'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打包私有化镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!antgo package --name=metricdepth --mode=grpc --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 部署服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!antgo deploy --ip=remote_machine_ip --port=80"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
